---
title: "[ë…¼ë¬¸ë¦¬ë·°]Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals"

categories: 
  - GR

toc: true
toc_sticky: true

date: 2022-12-22
last_modified_at: 2022-12-22 
---

## 1. ë¬¸ì œ ì •ì˜(Problem Set)
### Lack of Supervision signals at Intermediate steps.
Multi-hop Knowledge base question answering(KBQA)ì˜ ëª©í‘œëŠ” Knowledge base(Knowledge graph)ì—ì„œ ì—¬ëŸ¬ í™‰ ë–¨ì–´ì ¸ ìˆëŠ” Answer entity(node)ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤.
ê¸°ì¡´ì˜ KBQA taskëŠ” <span style = "color:green">Training ì¤‘ê°„ ë‹¨ê³„(Intermediate Reasoning Step) Supervision signalì„ ë°›ì§€ ëª»í•œë‹¤.</span> ë‹¤ì‹œë§í•´, 
feedbackì„ final answerí•œí…Œë§Œ ë°›ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ê³  ì´ëŠ” ê²°êµ­ í•™ìŠµì„ unstableí•˜ê³  ineffectiveí•˜ê²Œ ë§Œë“ ë‹¤.

<p align="center">
<img width="700" alt="1" src="https://user-images.githubusercontent.com/111734605/210034900-0bceb022-2127-41b6-a52c-3c4a9512365d.png">
</p>

Figure 1.  
Qusetion: What types are the film starred by actors in the *nine lives of fritz the cat*?
- Start node(Topic Entity)  = ì´ˆë¡ìƒ‰ ë…¸ë“œ 
- Final Node(Answer Entity) = ë¹¨ê°„ìƒ‰ ë…¸ë“œ
- Answer Path    = ë¹¨ê°„ìƒ‰ Path
- Incorrect Path = íŒŒë€ìƒ‰ Path, íšŒìƒ‰ Path

ì—¬ê¸°ì„œ ì¤‘ê°„ë‹¨ê³„ì—ì„œ Supervision signalì´ ë¶€ì¡±í•  ê²½ìš° ë°œìƒí•˜ëŠ” ê²½ë¡œê°€ ë°”ë¡œ **íŒŒë€ìƒ‰**ì´ë‹¤. ë…¼ë¬¸ì—ì„œëŠ” ì´ ê²½ë¡œë¥¼ Spurious fowrward path(ê°€ì§œ ê²½ë¡œ)ë¼ ëª…ì¹­í–ˆë‹¤. 

<span style = "font-size:120%">**ì°¸ê³ **</span>  
KBQA taskì—ì„œ Input data
- Ideal Case: <*question, relation path* >
- In this Paper: <*question, answer* >

<span style = "font-size:120%">**What we need to solve?**</span>  
<span style ="color:green">**Intermediate Reasoning Stepì— Supervision Signalì„ í†µí•´ Feedbackì„ í•˜ì—¬ ë” ì˜ Training**</span>ë˜ê²Œ í•œë‹¤.



## 2. Method  
### 1) Modeling 
- Teacher & Student Network
- Neural State Machine(NSM)
- Bidirectional Reasoning Mechanism

### 2) Teacher - Student Network  
#### (1) Overview    
```
The main idea is to train a student network that focuses on the multi-hop KBQA task itself, while another teacher
network is trained to provide (pseudo) supervision signals (i.e., inferred entity distributions in our task) at 
intermediate reasoning steps for improving the student network.
```
í•™ìƒ ë„¤íŠ¸ì›Œí¬ëŠ” multi-hop KBQAë¥¼ í•™ìŠµí•˜ëŠ” í•œí¸, ì„ ìƒ ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” <span style ="color:green">Intermediate Supervision Signal</span>ì„ ë§Œë“¤ì–´ í•™ìƒ ë„¤íŠ¸ì›Œí¬ë¡œ ë„˜ê²¨ì¤€ë‹¤.
ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ í•™ìƒ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë” í•™ìŠµì´ ì˜ë˜ê²Œë” í•œë‹¤.

### 3) Student Network  
ì„ ìƒ-í•™ìƒ ë„¤íŠ¸ì›Œí¬ì—ì„œ í•™ìƒ ë„¤íŠ¸ì›Œí¬(Student Network)ê°€ Main modelì´ë‹¤. í•™ìƒ ë„¤íŠ¸ì›Œí¬ì˜ ëª©í‘œëŠ” Visual question answeringìœ¼ë¡œë¶€í„° ì •ë‹µì„ ì°¾ëŠ” ê²ƒì´ë‹¤. 
í•™ìƒ ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” NSM(Neural State Machine) ì•„í‚¤í…ì³ë¥¼ ì´ìš©í•œë‹¤.

#### (1) NSM(Neural State Machine)

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/210039872-680ef240-219b-4a2c-9e81-421ab3d22fa5.png">
</p>

- Given an image, construct a 'Scene Graph'
- Given a question, extract an 'Instruction Vector'

Inputìœ¼ë¡œ ì´ë¯¸ì§€ì—ì„œ ë½‘ì•„ë‚¸ Scene graphì™€, ì§ˆë¬¸ì—ì„œ ë½‘ì•„ë‚¸ Intruction vectorê°€ Inputìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤.

<span style = "font-size:120%">**Student Network Architecture**</span>    
Student Networkì€ NSM ì•„í‚¤í…ì³ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. NSM ì•„í‚¤í…ì³ëŠ” Scene Graphì™€ Instruction Vectorë¥¼ ê°ê° ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ìœ¼ë¡œë¶€í„° ì¶”ì¶œí•´ë‚´ë©´ ì´ê±¸ Inputìœ¼ë¡œ ë°›ì•„ ì •ë‹µì„ ì°¾ì•„ë‚´ê²Œ
ëœë‹¤.

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/209019844-d2d7e641-295f-4721-b589-da131f5dde9d.png">
</p>

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/210233075-7c40808e-0e59-4c22-981a-ce481268fd48.png">
</p>    
<center><span style = "font-size:80%">Student Network Equation Table</span></center>


#### (2-1) Instruction Component    
1. Natural Language Questionì´ ì£¼ì–´ì§€ë©´ ì´ê±¸ Series of instruction vectorë¡œ ë°”ê¾¸ê³ , ì´ Instruction vectorëŠ” resoning processë¥¼ controlí•œë‹¤.  
2. Instruction Component ğŸ¡„ query embedding + instruction vector  
3. instruction vectorì˜ ì´ˆê¸°ê°’ì€ zero vectorì´ë‹¤.  
4. GloVe ì•„í‚¤í…ì³ë¥¼ í†µí•´ query ë‹¨ì–´ë“¤ì„ ì„ë² ë”©í•˜ê³ , ì´ë¥¼ LSTM ì¸ì½”ë”ì— ë„£ì–´ Hidden stateë¥¼ ë½‘ì•„ë‚¸ë‹¤.    
   (Hidden Stateì‹ $$ h_l $$ì´ê³ , $$l$$ì€ queryì˜ ê¸¸ì´)  

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/210257037-542d9aaa-ec19-46e6-be97-9a4d61354f16.png">
</p>     
<center><span style = "font-size:80%">Instruction Component</span></center>  

- query Embeddingê³¼ jë²ˆì§¸ hidden stateë¥¼ element wise productí•´ì„œ Softmaxë¥¼ ë¨¹ì¸ë‹¤.
  - $$q^{(k)}$$ì˜ ì‹ì€ Instruction vectorì— weighted ì²˜ë¦¬ëœ ê²ƒì´ë‹¤.
  - ì¦‰, ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ì—¬ ì²˜ë¦¬í•œ ê²ƒì´ë‹¤.
  - ê·¸ëŸ¬ë©´ Instruction vectorì—ì„œ ì˜í–¥ë ¥ í° ë¶€ë¶„ë§Œ ë½‘ì•„ë‚´ê² ë‹¤.
  - ì¦‰, queryì— í°ê°’ì´ ìˆëŠ”ê±¸ ë½‘ì•„ë‚´ëŠ” ê²ƒ 

Insteruction vectorë¥¼ í•™ìŠµí•˜ëŠ”ë° ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ë§¤ Time stepë§ˆë‹¤ queryì˜ íŠ¹ì •í•œ ë¶€ë¶„ì— <span style = "font-size:110%">**Attention**</span>ì„ ì·¨í•˜ëŠ” ê²ƒì´ë‹¤.
ì´ëŸ¬í•œ ê³¼ì •ì´ ê²°êµ­ query representationì„ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ í•  ìˆ˜ ìˆê²Œë˜ê³  ë”°ë¼ì„œ **ì´ì „ì˜ Instruction vectorë“¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ì˜ ì·¨í•©**í•  ìˆ˜ ìˆë‹¤. ì–»ì€ Instruction
vectorë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ í‘œí˜„í•˜ë©´ $$[i_{k=1}^j]$$ì´ë‹¤. 

#### (2-2)Attention Fuctionì´ë€?  

<p align="center">
<img width="" alt="500" src="https://user-images.githubusercontent.com/111734605/210244763-6df0807b-7e7f-4d4a-a73b-f100734ee83e.png">
</p>     
<center><span style = "font-size:80%">Instruction Component</span></center>

ì–´í…ì…˜ í•¨ìˆ˜ëŠ” Query, Key, Valueë¡œ êµ¬ì„±ëœ í•¨ìˆ˜ì´ë‹¤.  
<center>$$Attention(Q,K,V) \; = Attention \, Value $$</center>  
<center>
$$\begin{aligned}
Q &: Query  \\
K &: Key\\
V &: Value\\
\end{aligned}$$
</center>

ì–´í…ì…˜ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ **'ì¿¼ë¦¬(Query)'**ì— ëŒ€í•´ ëª¨ë“  **'í‚¤(Key)'**ì˜ ìœ ì‚¬ë„ë¥¼ ê°ê° êµ¬í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³ , ì´ ìœ ì‚¬ë„ë¥¼ í‚¤(Key)ì™€ ë§¤í•‘ë˜ì–´ ìˆëŠ” ê°ê°ì˜ **'ê°’(Value)'**ì— ë°˜ì˜í•´ì¤ë‹ˆë‹¤. ê·¸ë¦¬ê³  'ìœ ì‚¬ë„ê°€ ë°˜ì˜ëœ'ê°’ì„ ëª¨ë‘ ë”í•´ì„œ ë¦¬í„´í•˜ê³ , ì–´í…ì…˜ ê°’ì„ ë°˜í™˜í•œë‹¤.

#### (3) Reasoning Component

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/210257533-069772df-1a82-4dca-9b02-bc8bcb8bfd00.png">
</p>     
<center><span style = "font-size:80%">Reasoning Component</span></center>  

Reasoning Component(ì¶”ë¡  ìš”ì†Œ)ë¥¼ êµ¬ì¡°ì™€ ê·¸ ìˆ˜ì‹ì€ ìœ„ì™€ ê°™ë‹¤. ë¨¼ì €, Instruction Vector $$i^{(k)}$$ë¥¼ Instruction Component ê³¼ì •ì„ í†µí•´ ì–»ì—ˆê³  ì´ë¥¼ Reasoning Componentì—ì„œ
Guide Signalë¡œì„œ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤. Reasoning Componentì˜ Inputê³¼ Outputì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
- Input : **í˜„ì¬ stepì˜ instruction vector** + **ì´ì „ stepì˜ entity distributionì™€ entitiy embedding**
- Output: entity distribution $$p^{(k)}$$ + entitiy embedding $$e^{(k)}$$
  - Entity Embeddingì˜ ì´ˆê¸°ê°’ì¸ $$e^{(0)}$$ì€ (2)ë²ˆì‹ì´ë‹¤.
  - $$\sigma$$ëŠ” Nonlinearityë¥¼ ì˜ë¯¸(Nonlinear fuction)
  - $$<e^{\prime}, r, e>$$ëŠ” Tripleì´ë¼í•œë‹¤. ë…¸ë“œ(Entity), ì—£ì§€, ë…¸ë“œ ìˆœì„œì´ë‹¤.


**(2)ë²ˆ ì‹ Entity Embeddingì˜ ì´ˆê¸°ê°’**: 2ë²ˆì‹ì„ ìì„¸íˆë³´ë©´ Entityì˜ ì„ë² ë”©ì‹ì€ ê²°êµ­ Weight Sumì— Nonlinear functionì„ ë¨¹ì¸ ê²ƒì´ë‹¤. ì´ì „ì˜ ì—°êµ¬ë“¤ê³¼ëŠ” ë‹¤ë¥´ê²Œ ì´ ë…¼ë¬¸ì—ì„œëŠ” **ì—”í‹°í‹°ë¥¼ ì¸ì½”ë”©í•˜ëŠ”ë° <span style ="color:green">íŠ¸ë¦¬í”Œ(ë…¸ë“œì™€ ë…¸ë“œ, ì—£ì§€ë¡œ í‘œí˜„ëœ Relation)ì˜ ì •ë³´</span>ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©**í•œë‹¤. ê²Œë‹¤ê°€ ì´ë ‡ê²Œ ì •ë³´ë¥¼ í™œìš©í•˜ë©´ **ì—”í‹°í‹° ë…¸ì´ì¦ˆì— ëŒ€í•œ ì˜í–¥ë ¥ì´ ì¤„ì–´ë“ ë‹¤.** ì¶”ë¡  ê²½ë¡œë¥¼ ë”°ë¼ ì¤‘ê°„ ì—”í„°í‹°ì˜ ê²½ìš° ì´ëŸ¬í•œ ì—”í„°í‹°ì˜ ì‹ë³„ìê°€ ì¤‘ìš”í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— e(0)ë¥¼ ì´ˆê¸°í™”í•  ë•Œ eì˜ ì›ë˜ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ì™œëƒí•˜ë©´ ì¤‘ê°„ ì—”í‹°í‹°ë“¤ì˜ **relation**ë§Œì´ ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì´ë‹¤.

**(3)ë²ˆ ì‹ Match vector**: Triple($$<e^{\prime}, r, e>$$)ì´ ì£¼ì–´ì¡Œì„ë•Œ Match vector $$m_{<e^{\prime}, r, e>}^{(k)}$$ëŠ” (3)ë²ˆ ì‹ê³¼ ê°™ë‹¤. Instruction vectorì™€ Edge(Relation)ì— ê°€ì¤‘ì¹˜ë¥¼ ê³±í•œ ê°’ê³¼ Element wise productí•œ ê°’ì„ Nonlinear functionì„ ë¨¹ì¸ ê²ƒì´ë‹¤. ì´ ì‹ì˜ ì˜ë¯¸ë¥¼ ë³´ìë©´, Match vectorë¼ëŠ” ê²ƒì€ ê²°êµ­ <span style = "color:green">ì˜¬ë°”ë¥¸ Relationì„ ë‚˜íƒ€ë‚´ëŠ”, ì˜¬ë°”ë¥¸ Edgeì— ëŒ€í•´ì„œ ë” ë†’ì€ ê°’ì„ ë¶€ì—¬í•´ ì—”í‹°í‹°ê°€ ê·¸ ì—£ì§€ë¥¼ ë”°ë¼ê°€ê²Œë” ê°’ì„ ë¶€ì—¬í•˜ëŠ” ê²ƒ</span>ì´ë‹¤. ë”°ë¼ì„œ, 'ì˜¬ë°”ë¥¸ Edgeë¥¼ ë§¤ì¹­í•œë‹¤'ë¼ëŠ” ì˜ë¯¸ë¡œ Match vectorë¼ê³  í•œë‹¤. 

**(4)ë²ˆ ì‹**: Match vectorë“¤ì„ í†µí•´ì„œ ì˜¬ë°”ë¥¸ Engeë¥¼ ì°¾ê³ ë‚œ í›„ ìš°ë¦¬ëŠ” <span style = "color:green">**ì´ì›ƒ Tripleë“¤ë¡œë¶€í„° matching messageë¥¼ ì§‘ê³„(aggregate)**í•œë‹¤. ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ ì¶”ë¡  ë‹¨ê³„ì—ì„œ ì–¼ë§ˆë‚˜ ë§ì€ **ì–´í…ì…˜**ì„ ë°›ëŠ”ì§€ì— ë”°ë¼ **ê°€ì¤‘ì¹˜ë¥¼ í• ë‹¹**</span>í•œë‹¤. $$p_{e^{\prime}}^{(k-1)}$$ì€ $$e^{\prime}$$ëŠ” ë§ˆì§€ë§‰ ì¶”ë¡  ìŠ¤íƒ­ì—ì„œ Entityì— í• ë‹¹ëœ í™•ë¥ ì´ë‹¤.      
<center>$$(4) \; \widetilde{e} \, = \, \sum_{<e^{\prime}, r,e> \in {\mathscr{N}_e}}p_{e^\prime}^{(k-1)} \cdot m_{<e^{\prime}, r, e>}^{(k)}$$</center>

**(5)ë²ˆ ì‹ Entity Embedding Update**: Entity Embeddingì€ Feed Forward Neural Networkë¥¼ í†µí•´ ì—…ë°ì´íŠ¸ í•œë‹¤. ì´ FFNì€ inputìœ¼ë¡œ ì´ì „ ì„ë² ë”© ê°’ì¸ $$e^{k-1}$$ì™€ relation-aggregate ì„ë² ë”©ì¸ $$\widetilde{e}^{(k)}$$
ë‘ ê°’ì„ ë°›ëŠ”ë‹¤.   
<center>$$(5) \; e^{(k)} = FFN([e^{(k-1)};\widetilde{e}^{(k)}])$$</center>

**(6)ë²ˆ ì‹**: ì´ëŸ¬í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ relation path(Topic Entity  âœ Answer Entity)ì™€ ì§ˆë¬¸ì˜ ì¼ì¹˜ ì •ë„(Matching degree with question) ëª¨ë‘  ë…¸ë“œ ì„ë² ë”©(Node Embedding)ìœ¼ë¡œ ì¸ì½”ë”© ë  ìˆ˜ ìˆë‹¤.  
<center> $$(6) \; p^{k} = softmax(E^{(k)^T}w)$$</center>  
- $$E^{(k)}$$ëŠ” kë²ˆì§¸ stepì—ì„œ ì—”í‹°í‹°ë“¤ì˜ ì„ë² ë”© ë²¡í„°ë“¤ì„ columnë°©í–¥ìœ¼ë¡œ concatenationí•œ ê²ƒì´ë‹¤. 
- $$E^{(k)}$$ëŠ” ê²°êµ­ (5)ë²ˆ ì‹ìœ¼ë¡œë¶€í„° Updateëœ Entity Embedding í–‰ë ¬ì´ë‹¤. 
- $$w$$ëŠ” Entity Distributionì¸ $$p^{(k)}$$ë¡œë¶€í„° ìœ ë„ëœ íŒŒë¼ë¯¸í„°ì´ë‹¤.

#### (4) Discussion
- Student Networkì˜ NSM modelì€ Two-foldì´ë‹¤.  
  1. Teacher Networkë¡œ ë¶€í„° <span style = "color:green">**ì¤‘ê°„ ì—”í‹°í‹° ë¶„í¬(Intermediate entity distribution)ì„ Supervision signalë¡œ**</span> Student Networkì— ì´ìš©í•œë‹¤ 
    - ê¸°ì¡´ì˜ KBQA ì—°êµ¬ë“¤ì€ ì´ëŸ° ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ì—”í‹°í‹° ë¶„í¬ë¥¼ ì´ìš©í•˜ì§€ ì•ŠìŒ!!
  2. NSMì€ ì£¼ì–´ì§„ **Knowledge graph**ì— ëŒ€í•´ ì—„ì²­ë‚œ <span style = "color:green">**ì¶”ë¡  ëŠ¥ë ¥(reasoning capacity)**</span>ì„ ë³´ì—¬ì£¼ëŠ” GNN ëª¨ë¸ì´ë‹¤. 
    - ì—”í‹°í‹° ë¶„í¬ì™€ ì—”í‹°í‹° ì„ë² ë”©ì„ í•™ìŠµí•˜ëŠ” ê²ƒì€ ê²°êµ­ GNNì˜ ì¼ë°˜ì ì¸ <span style = "color:green">"ì „ì‚¬ í›„ ì§‘ê³„(*propagate-then-aggregate*)" ë©”ì»¤ë‹ˆì¦˜</span>ì„ ì˜ ë°˜ì˜í•´ì¤€ë‹¤.

- NSMì€ Scene graphì™€ instruction vectorë¥¼ ì´ìš©í•´ ì¶”ìƒì ì¸ ì ì¬ ê³µê°„ì—ì„œ ì‹œê°ì  ì¶”ë¡ ì„ í•˜ê¸°ìœ„í•œ ëª¨ë¸ì´ë‹¤. ì´ë¥¼ Multi-hop KBQAì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ ë°©ë²•ì„ ì‚¬ìš©í•˜ì˜€ë‹¤.
  1. ì—”í‹°í‹°ë“¤ì— ê´€ë ¨ëœ **ê´€ê³„ ì„ë² ë”©(relation embedding)**ì„ ì§‘ê³„í•˜ì—¬ ë…¸ë“œ ì„ë² ë”©ì„ ì´ˆê¸°í™”í•œë‹¤.
    - ì‹ (2), ì—”í‹°í‹°ì˜ ì´ˆê¸°ê°’ ë°©ë²•ì€ ê²°êµ­ ì¢€ ë” ìœ ì˜ë¯¸í•œ ì—”í‹°í‹°ì˜ relationì— ì´ˆì ì„ ë§ì¶°, ë…¸ì´ì¦ˆ ì—”í‹°í‹°ì˜ ì˜í–¥ë ¥ì„ ê°ì†Œì‹œí‚¨ë‹¤.
  2. **ì´ì „ ì„ë² ë”©** $$e^{(k-1)}$$ì™€ **relation-aggregated ì„ë² ë”©** $$\widetilde{e}^{(k)}$$ì™€ í†µí•©í•´ì„œ ì—”í‹°í‹° ì„ë² ë”©ì„ ì—…ë°ì´íŠ¸ í•œë‹¤.
      (Original NSMì€ ë‘ factorë¥¼ ê°ê° ëª¨ë¸ë§í•¨.)
  
### 4) Teacher-Network    
Teacher Network ëª¨ë¸ì€ Student Networkì™€ëŠ” ê·¸ ì¡´ì¬ ëª©ì  ìì²´ê°€ ë‹¤ë¥´ë‹¤. Teacher NetworkëŠ” <span stlye = "color:green">**ì¤‘ê°„ ì¶”ë¡  ë‹¨ê³„ì—ì„œ ì‹ ë¢°ê°€ëŠ¥í•œ ì—”í‹°í‹°(reliable entity)ë¥¼ í•™ìŠµí•˜ê±°ë‚˜ ì¶”ë¡ **</span>í•œë‹¤. ì°¸ê³ ë¡œ, Teacher Networkë¥¼ í•™ìŠµí• ë•ŒëŠ” Unlabeling ëœ ë°ì´í„°ë“¤ì„ ì‚¬ìš©í•œë‹¤.

ì´ëŸ¬í•œ ì´ìœ ë¡œ ë…¼ë¬¸ì—ì„œëŠ” Bidirectional Search ì•Œê³ ë¦¬ì¦˜ì„ ì°¸ê³ í•´ <span style = "color:green">**Bidirectional reasoning mechanism**</span>ì„ ë„ì…í–ˆë‹¤. ì´ ë©”ì»¤ë‹ˆì¦˜ì„ í™œìš©í•˜ì—¬
ì¤‘ê°„ ì¶”ë¡  ë‹¨ê³„ì—ì„œì˜ Teacher Network í•™ìŠµì„ í–¥ìƒì‹œì¼°ë‹¤. Bidirectional reasoning mechanismì„ *forward reasoning*ì´ë¼ê³  í•œë‹¤.

#### (1) Bidirectional Reasoning for Multi-hop KBQA
ê¸°ì¡´ì˜ Knowledge Graphì—ì„œëŠ” Topic entityì—ì„œ Answer entityë¡œ í•œë°©í–¥ íƒìƒ‰ì„ í†µí•´ ì •ë‹µì— ì ‘ê·¼í–ˆë‹¤. í•˜ì§€ë§Œ, ë…¼ë¬¸ì—ì„œëŠ” **ì–‘ë°©í–¥ íƒìƒ‰(Bidirectional Search)**ë¥¼ ì‘ìš©í•´ ì–‘ë°©í–¥ ì¶”ë¡ 
ì„ êµ¬í˜„í–ˆë‹¤.  
- Bidirectional Reasoning Mechanism
  1. Topic Entity  âœ Answer Entity
  2. Answer Entity âœ Topic Entity

ê¸°ì¡´ì˜ ì—°êµ¬ëŠ” ëª¨ë‘ 1ë²ˆì„ ê¸°ì¤€ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” 2ë²ˆì„ í™œìš©í•œ ê²ƒì´ë‹¤. ì•„ì´ë””ì–´ëŠ” ë‘ ì¶”ë¡  í”„ë¡œì„¸ìŠ¤ê°€ ì¤‘ê°„ ë‹¨ê³„ì—ì„œ ì„œë¡œ ë™ê¸°í™”ë˜ë„ë¡ í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¤ì‹œ ë§í•´,
forward ë°©í–¥ì—ì„œ kë²ˆì§¸ ì—”í‹°í‹° ë¶„í¬ì¸ $$p_f^{(k)}$$ì™€ backward ë°©í–¥ì˜ (n-k)ë²ˆì§¸ ì—”í‹°í‹° ë¶„í¬ì¸ $$p_b^{(n-k)}$$ì¼ ë•Œ, ë§Œì•½ ë‘ ì¶”ë¡  í”„ë¡œì„¸ìŠ¤ê°€ ì•ˆì •ì ì´ê³  ì •í™•í•˜ë‹¤ë©´ ë‘ ë¶„í¬ëŠ”
ê·¸ ê°’ì´ ë¹„ìŠ·í•˜ê±°ë‚˜ ì¼ì •í•  ê²ƒì´ë‹¤. âœ $$p_f^{(k)} \approx p_b^{(n-k)}$$

#### (2) Reasoning Architecture  
<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/210313258-d7bfb2f5-11e8-4bce-8631-105c23e8afce.png">
</p>

#### (3) Parallel Reasoning
Figure 3ì— (a)ë²ˆì§¸ì™€ ê°™ì´ Instruction vectorë¥¼ ê³µìœ í•˜ì§€ ì•Šê³  **ì„œë¡œ ë‹¤ë¥¸ NSM**ì„ ì‚¬ìš©í•´ forwardì™€ backward reasoningì„ **ê°ê°** ì§„í–‰í•œë‹¤. ë‘ NSM networkëŠ” ë°˜ë“œì‹œ Isolatedí•˜ë©°
**ì„œë¡œ ì–´ë– í•œ íŒŒë¼ë¯¸í„°ë„ ê³µìœ í•˜ì§€ ì•ŠëŠ”ë‹¤.** ë‹¨ì§€ ê·¸ ë‘ í”„ë¡œì„¸ìŠ¤ ì‚¬ì´ì˜ ì¤‘ê°„ ì—”í‹°í‹° ë¶„í¬ì— ì„œë¡œ ëŒ€ì‘ ì œì•½(Correspondence Constraint)ë§Œ í†µí•©í•˜ëŠ” ê²ƒë§Œ ê³ ë ¤í•œë‹¤.


#### (4) Hybrid Reasoning

Hybrid Reasoning ë°©ë²•ì—ì„œëŠ” Instruction Componentë¥¼ ê³µìœ í•˜ê³ , Cycle Pipeline(ì›í˜• íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ)ë¡œ êµ¬ì„±í–ˆë‹¤. ë˜í•œ ëŒ€ì‘ ì œì•½ ì™¸ì—ë„, ê°™ì€ Instruction Vectorë¥¼ ë°›ëŠ”ë‹¤.
**forward reasoningì˜ ë§ˆì§€ë§‰ ìŠ¤í…ì€ backward reasoningì˜ ì²«ë²ˆì§¸ ê°’ì´ ëœë‹¤.** ì´ë¥¼ ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

<p align="center">
<img width="350" alt="1" src="https://user-images.githubusercontent.com/111734605/210319909-88e3450a-3069-411f-9f3c-9a8823c76433.png">
</p>

Figure 3ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´, Parallel reasoningì´ ì¢€ ë” ëŠìŠ¨í•œ í†µí•©ì„ ê°€ì§„ ë°˜ë©´, Hybrid reasoningì€ forwardì™€ backward reasoning ê³¼ì •ì˜ ì •ë³´ ì‚¬ì´ì— ë” ê¹Šì€ í†µí•©ì„
í•„ìš”ë¡œ í•œë‹¤. ì—¬ê¸°ì„œ ì£¼ì˜í•  ê²ƒì€, ì¼ë°˜ì ì¸ BFSì™€ëŠ” ë‹¤ë¥´ê²Œ ì—­ë°©í–¥ ì¶”ë¡ ì´ ì •ë°©í–¥ ì¶”ë¡ ì˜ ì™„ë²½í•œ ì—­ê³¼ì •ì€ ì•„ë‹ˆë¼ëŠ” ê²ƒì´ë‹¤. ì™œëƒí•˜ë©´ ë‘ ê³¼ì •ì€ ì„œë¡œ ë‹¤ë¥¸ semantic(ì˜ë¯¸ë¡ )ì— ëŒ€í•´ 
í•´ë‹¹í•œë‹¤. ì¦‰, multi-hopì—ì„œ ê°™ì€ **entityë¥¼ ê°™ì€ edgeë¥¼ í†µí•´ ê°„ë‹¤ê³  í•˜ë”ë¼ë„, ë°©í–¥ì´ ë°˜ëŒ€ì´ë©´ ê·¸ ì˜ë¯¸ëŠ” ë‹¤ë¥´ë‹¤.**

ì´ëŸ¬í•œ ì ì„ ê³ ë ¤í• ë•Œ, <span style = "color:green">forwardì˜ ë§ˆì§€ë§‰ ì¶”ë¡  ë‹¨ê³„ì˜ ê°’ì„ backwardì˜ ì´ˆê¸°ê°’ìœ¼ë¡œ **ì¬í™œìš©**í•˜ê³ </span> ì´ëŸ¬í•œ ë°©ì‹ì€ ê²°êµ­ backward reasoningì—ì„œ forward reasoningì— ê´€í•œ ì •ë³´ë¥¼
ë” ë§ì´ ë°›ëŠ”ê²ƒì´ë˜ë¯€ë¡œ forward reasoningì„ ì¶”ì í•˜ëŠ”ë° ë” í° ë„ì›€ì´ ëœë‹¤.

### 5) Teacher-Student framework ì´ìš©í•œ í•™ìŠµ

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/210330914-04d911e8-85f9-4741-b296-c46344177007.png">
</p>

#### (1) Teacher Network ìµœì í™”
Teacher Networkì˜ ë‘ê°€ì§€ ì¶”ë¡  ì•„í‚¤í…ì³ëŠ” ê°™ì€ ë°©ì‹ìœ¼ë¡œ ìµœì í™”í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ 1) Reaspning loss ì™€ 2) Correspondence lossì´ë‹¤. 

- Reasoning Loss [ì‹ (9)]
  <center>![image](https://user-images.githubusercontent.com/111734605/210331487-bbdc9df2-2a34-4e91-babb-2828535082fb.png)</center>
  - reasoing lossëŠ” ì—”í‹°í‹°ë¥¼ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ë‚˜íƒ€ë‚´ëŠ”ê°€ë¥¼ ì˜ë¯¸í•˜ë©°, ì´ëŠ” ë‘ directionìœ¼ë¡œ ë¶„í•´ëœë‹¤.
  - $$p_f^{(n)}$$ ì™€ $$p_b^{(n)}$$ì€ ê°ê° forwardì™€ backward ì¶”ë¡  í”„ë¡œì„¸ìŠ¤ì˜ ë§ˆì§€ë§‰ ì—”í‹°í‹° ë¶„í¬ì´ë‹¤.
  - KL divergenceëŠ” asymmetricí•œ ë°©ë²•ì´ë‹¤.
  - $$p_f^{*}$$ ì™€ $$p_b^{*}$$ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„œ ì›ë˜ì˜ ì—”í‹°í‹°(ground-truth entity)ë¥¼ ì£¼íŒŒìˆ˜ ì •ê·œí™” ì—”í‹°í‹°ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤.
  - ë” ì •í™•í•˜ê²ŒëŠ” ê·¸ë˜í”„ì—ì„œ $$ k $$ ì—”í‹°í‹°ê°€ ground-truth entityì´ë©´ ë§ˆì§€ë§‰ ë¶„í¬ì— $$\frac{1}{k}$$ì˜ í™•ë¥ ì´ í• ë‹¹ëœë‹¤. 

- Correspondence Loss [ì‹ (10)]
  - ì°ìŠ¨-ì…°ë„Œ divergenceë¥¼ ì´ìš©í•œë‹¤. JS DivergenceëŠ” symmetricí•œ ë°©ë²•ì´ë‹¤. ì´ë¥¼ Lagrange Multiplierë¥¼ ì´ìš©í•´ í‘œí˜„í•˜ë©´ (10)ì‹ê³¼ ê°™ì´ ëœë‹¤.
  
#### (2) Student Network ìµœì í™”
NSM ëª¨ë¸ì„ Student Network ëª¨ë¸ì— ì ìš©í•´ forward reasoningì„ ìˆ˜í–‰í–ˆë‹¤. ê²Œë‹¤ë¼ reasoning lossë¥¼ ê³ ë ¤í•˜ì—¬, student networkì˜ predictionê³¼ teacher networkì˜ 
supervision signalì˜ lossë¥¼ í†µí•©í•œë‹¤. ì´ë¥¼ ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´  (12)ì‹ì´ ëœë‹¤.

Teacher Networkì˜ ìµœì í™”ê°€ ì™„ë£Œë˜ë©´ ë‘ ì¶”ë¡  í”„ë¡œì„¸ìŠ¤ë¡œë¶€í„° ì¤‘ê°„ ì—”í‹°í‹° ë¶„í¬(Intermediate Entity Distribution)ë¥¼ ì–»ê²Œ ëœë‹¤. ì´ ë‘ ì¤‘ê°„ ì—”í‹°í‹° ë¶„í¬ë¥¼
Supervision signalë¡œ ì—¬ê¸°ê³  í‰ê· ì„ ì·¨í•˜ë©´ (11)ì‹ì´ ëœë‹¤. 
- $$p_t^{(k)}$$ì™€ $$p_s^{(k)}$$ëŠ” kë²ˆì§¸ ìŠ¤í…ì—ì„œ Student networkì™€ Teacher networkì˜ ì¤‘ê°„ ì—”í‹°í‹° ë¶„í¬ì´ë‹¤. $$\lambda$$ Lagrange Multiplierë‹¤. 

#### (3) Discussion
ì‹¤ì œë¡œ ë§ì€ KBQA ëª¨ë¸ë“¤ì€ ì¤‘ê°„ ì¶”ë¡  ë‹¨ê³„ì—ì„œ labeled dataëŠ” ê±°ì˜ ì‚¬ìš©ë˜ì§€ ëª»í•œë‹¤. ì¦‰, Supervision signalì´ ë¶€ì¡±í•˜ë‹¤. ì´ ë…¼ë¬¸ì˜ í•µì‹¬ì€, ì¶”ê°€ì ìœ¼ë¡œ Labeled dataë¥¼
ì‚¬ìš©í•˜ì§€ ì•Šê³ , <span style = "color:green">Teacher Networkì˜ **Bidirectional Reasoning Mechanism**ì„ ì´ìš©í•´ì„œ **ì¤‘ê°„ ì—”í‹°í‹° ë¶„í¬**ë¥¼ ë§Œë“¤ì–´ë‚´ê³ , ì´ë¥¼ Supervision signalë¡œ Student Networkì—ì„œ ì´ìš©í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„ ë†’ì´ëŠ” ê²ƒ</span>ì´ë‹¤. 

## 3. Result
### 1) Data Set  
<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/210343881-5c3a8b83-b814-4236-87f0-a8ce29977c37.png">
</p>  

### 2) Experimental Setting
- KV-Mem
- GraftNet
- PullNet
- SRN
- EmbedKGQA
- $$NSM_{+p}$$, $$NSM_{+h}$$, NSM  

### 3) Result

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/210346566-3b68287f-a1eb-4e05-9e26-0d731b7039b9.png">
</p>  

- ëŒ€ì²´ì ìœ¼ë¡œ MetaQA Datasetì´ ìš°ìˆ˜í•œ ì„±ì ì„ ë³´ì„. MetaQAëŠ” ë°ì´í„° ìˆ˜ê°€ ë§¤ìš° ë§ë‹¤.
- Hybrid reasoningì´ ëŒë‹¤ ê°’ì´ ì‘ì„ ë•Œ(e.g 0.05) performanceê°€ ì¢‹ë‹¤. ë°˜ë©´ Parallel reasoningì€ í° ëŒë‹¤ ê°’(e.g. 1.00)ì—ì„œ performanceê°€ ì¢‹ë‹¤.
  
<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/210346821-fd37bb43-60bb-4887-ada6-21376263593c.png">
</p>   
ì˜ˆì¸¡: Intermediate Entityë¥¼ ì–»ëŠ”ë° Student netë³´ë‹¤ Teacher netì´ ë” ì‹ ë¢°ì„± ìˆì„ ê²ƒì´ë‹¤.

- Figure 5
  - intermediat entityë¥¼ ì°¾ëŠ”ë° teacher netì´ ë” ìš°ìˆ˜í–ˆë‹¤. í•˜ì§€ë§Œ, 2nd-hopì—ì„œ performanceëŠ” student netì— ë¹„í•´ ì‚´ì§ ë–¨ì–´ì¡Œë‹¤.
  - Student NetworkëŠ” forward reasoningë§Œ ì´ìš©í•˜ê¸°ì—, 1st-hopì´ ë‹¤ë¥¸ subsequent-hopë³´ë‹¤ ì¤‘ìš”í•˜ë‹¤.

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/210348674-43f52d7d-4a5f-473d-ba39-404c13a62250.png">
</p>  

## 4. Contribution
- NSM modelì„ KBQAì— ì„±ê³µì ìœ¼ë¡œ ì ìš©í•˜ì˜€ë‹¤.
- Supervision Signal(Intermediate Entity Distribution)ì„ Teacher-Student Networkë¥¼ í†µí•´ ì„±ê³µì ìœ¼ë¡œ ì´ìš©í•˜ì—¬ Performanceë¥¼ ë†’ì˜€ë‹¤.
- KBQAì— ì–‘ë°©í–¥ íƒìƒ‰(Bidirectional Search)ì„ ì„±ê³µì ìœ¼ë¡œ ì ìš©í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„ ë†’ì˜€ë‹¤.

## 5. Reference

### 1) ë…¼ë¬¸ì„ ìœ„í•œ Basic Knowledge
- [Graphì˜ ê°œë…](https://meaningful96.github.io/datastructure/2-Graph/)
- [Cross Entropy, Jensen-Sharnnon Divergence](https://drive.google.com/file/d/18qhdvC_2B9LG7paPdAONARqj3DWxxa8h/view?usp=sharing)
- [Knowledge Based Learning](https://meaningful96.github.io/etc/KB/)
- [Reward Shaping](https://meaningful96.github.io/etc/rewardshaping/#4-linear-q-function-update)
- [Action Dropout](https://meaningful96.github.io/deeplearning/dropout/#4-test%EC%8B%9C-drop-out)
- [GloVe]()
- [BFS, DFS](https://meaningful96.github.io/datastructure/2-BFSDFS/)
- [Bidirectional Search in Graph](https://meaningful96.github.io/datastructure/3-Bidirectionalsearch/)
- [GNN](https://meaningful96.github.io/deeplearning/GNN/)
- [Various Types of Supervision in Machine Learning](https://meaningful96.github.io/etc/supervision/)
- [End-to-end deep neural network](https://meaningful96.github.io/deeplearning/1-ETE/)
- [NSM(Neural State Machine)](https://meaningful96.github.io/etc/NSM/)
  
### 2) Related Work
- Knowledge Base Question Answering
- Multi-hop Reasoning
- Teacher-Student Network

### 3) Reference  
[Paper](https://arxiv.org/pdf/2101.03737.pdf)
