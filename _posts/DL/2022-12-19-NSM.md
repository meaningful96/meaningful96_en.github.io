---
title: "[딥러닝]Neural State Machine(NSM)"

categories:
  - DeepLearning

toc: true
toc_sticky: true

date: 2022-12-19
last_modified_at: 2022-12-19
---

## 1. What is State Machine

### 1) Combinational Logiv VS Sequential Logic

#### Combinational Logic(조합논리)

<p align="center">
<img width="400" alt="1" src="https://user-images.githubusercontent.com/111734605/209858938-8b242041-1444-467f-a486-990fe9b0adf2.png">
</p>

Combinational Logic이라는 것은 어떤 모듈을 통과하는 Input과 Output의 상관 관계에 있어서, <span style = "color:green">**Output의 값이 오직
Input에 dependent한 것**</span>이다. 조합 논리 회로는 다시 말해서 **memory feedback loop가 없다.** 

Combinational Logic circuit에는 adder, Subtractor, Encoder, Decoder, Parallel adder, MUXm de-MUX등이 있다.
이러한 회로를 구성하는 가장 기본적인 gate들은 NAND, AND, NOR, 등의 logic gate들이 있다.

모든 Combination circuit에는 매우 간단하거나 매우 복잡할 수 있으며, 모든 조합 회로는 범용 게이트로 분류되기 때문에 NAND 및 NOR 게이트만으로 구현할 수 있다.

- Combinational Logic의 기능을 구체화 하는 방법
  1. Boolean Algebra
  2. Truth Table
  3. Logic Diagram

#### Sequential Logic(순차 논리)

<p align="center">
<img width="400" alt="1" src="https://user-images.githubusercontent.com/111734605/209860190-f63799c3-e885-42f4-aa2a-f9c063821d4f.png">
</p>

Sequential Logic은 Output이 회로에 들어오는 Input뿐만 아니라 메모리에 저장된 이전 상태에도 영향을 받는 로직이다. 즉 Output이 현재 Input과 이전 state에 dependent하다.

Sequential Logic circuit에는 Register, Latch, Flip-Flop등이 있다.

- Sequential Logic의 종류
  - Synchronous sequential logic(동기식 순차 논리)
    - 클럭을 이용하여 새로운 입력의 순차와 응답의 출력 생성이 일정한 시간 간격을 둔 상태에서 제어한다.
    - Clock Pulse 이용
  - Asynchronous sequential logic(비동기식 순차 논리)
    - 출력이 외부로부터의 관리에 의해서가 아니라 내부의 지연에 의해 일정하지 않은 시간 간격을 두고 발생한다.
    - State, Enable signal 이용
    
<p align="center">
<img width="70%" alt="1" src="https://user-images.githubusercontent.com/111734605/209861137-1b7f0cec-4f85-4bac-82ef-17d98712abd9.png">
</p>

### 2) State Machine
- Pic 1)
<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209862693-aebf8d75-ccaf-44b6-8329-99ab1888f0db.png">
</p>

- Pic 2)
<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209867119-6ad43e67-022b-4186-a779-c02e93fe11da.png">
</p>

- Moore  
  - output is synchronized with the clock
  - 무어 기계에서는 <span style = "color:green">**출력**이 오직 **현재상태**</span>로만 결정됩니다.
  - 즉 입력이 무엇인가에 상관없이, 현재 상태 그 자체가 출력이 되는 것입니다.
  - 무어 기계의 상태 그래프는 해당 상태와 연관된 출력을 가집니다.

- Mealy 
  - Output changes with input change during clock cycle
  - Output may be momentarily false due to input to FF output delay
  - 밀리기계는 <span style = "color:green">**출력**이 **현재상태**와 회로 입력에 의해 결정</span>됩니다.
  - 상태 그래프는 출력이 상태 사이의 간선에 대한 라벨로써 표시됩니다.

이처럼 State Machine이라는 것은 출력값이 단순 Input에 멈추지 않고 특정 상태에 영향을 받는 모델이다. 즉, State라는 특정 Case들이 존재하고 이 Case들이 다음 Output에 영향을 끼치는 아키텍쳐를 말한다. 어떤 특정 상태를 노드로 지정하고, 상태와 상태를 Edge로 transition하는 구조이다.


## 2. Neural State Machine(NSM)

### 1) Concept
NSM은 Neural Network와 Visual reasoning 관점 사이의 격차를 해소하고, 시각적 추론 작업을 보다 더 효과적으로 하기 위해 도입된 Neural Net 기반 State Machine이다. 
이미지가 Input으로 주어지면 먼저 representation과 연관된 확률적 그래프를 예측한다. 그런 다음 그래프에 **순차적 추론(Sequential Reasoning)**을 수행하여 주어진 질문(Question answering)에 답하거나 새로운 추론을 그리기 위해 노드를 반복적으로 통과한다.

기존의 단순한 Neural Network는 Graph와 Image를 분석하는데 서로 다른 유형의 아키텍쳐로 학습이 진행되었지만, 이 두 가지를 합쳐 시각적 그리고 언어적 양식을 모두 semantic concept-based representations(의미론적 개념 기반 표현)으로 변환하여 추상적인 latent space에서 작동해 투명성과 모듈화 그 자체를 향상시킨다.

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209869062-3bdd2022-75b6-4c80-be6d-f5e7e2a6453d.png">
</p>

By incorporating the concept of a state machine into neural networks, we are able to introduce a strong structural prior that enhances compositinality both in terms of
the representation, by having a structured graph to serve as our world model, as well as in terms of the computation, by performing sequential reasoning over such
graphs. 

상태 기계의 개념을 신경망에 통합함으로써, 우리는 이러한 그래프에 대해 순차적 추론을 수행함으로써 계산뿐만 아니라 우리의 세계 모델 역할을 할 구조적 그래프를 가짐으로써 표현 측면에서
복합성을 향상시키는 강력한 구조적 선행을 도입할 수 있다. 

### 2) NSM Concept 구체화
- 시각적 추론 및 질문 답변의 맥락에서 모델을 탐색
  - (Explore the model in the context of **visual reasoning** and **question answering**.)
- <span style = "color:green">신경 및 상징적 접근 방식의 장점을 결합</span>
  - (Combines the strengths of neural and symbolic approaches.)
- 우리는 주어진 예에서 새로운 예로 일반화하기 위한 개념을 형성
  - (form concepts to generalize from given examples to new ones)
- 우리의 **환경(State)을 대표하는 의미론적 세계 모델**을 구축
  - (build semantic world models to represent our environment)
- 사실에서 결론에 이르기까지 추론을 끌어냄
  - (draw inferences to proceed from facts to conclusions)

### 3) NSM 모델 
NSM 모델은 크게 두 가지 Stage로 구성된다.
- Learning(Modeling)
  - transforms the raw inputs into **abstract** semantic representations, and <span style ="color:green">**construct the state machine**</span>.
  - 원시 입력을 **추상적인** 의미 표현으로 변환하고 **상태 기계를 구성**한다.
  - **Image**  ➜ Scene graph, **Question** ➜ Instruction
- Inference
  - simulates an iterative computation over the machine, <span style ="color:green">**sequentially traversing**</span> the states until completion.
  - 기계를 통해 반복 계산을 시뮬레이션하여 완료될 때까지 **순차적**으로 상태를 통과한다.

> reasoning over the scene graph to compute an answer
> 정답을 계산하기 위해 장면 그래프에 대한 추론

#### Formal Definition

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209871090-e85f7b1e-3532-4217-95ff-8eb4261c5a8e.png">
</p>

#### Concepts Vocabulary

<p align="center">
<img width="70%" alt="1" src="https://user-images.githubusercontent.com/111734605/209871268-98d6d1fc-ee34-46ae-941f-f8c9d5a4d402.png">
</p>

- The model operates over a vocabulary of embedded concepts, atomic semantic units that represent aspects of the world.
  - 즉, 세상에 어떠한 의미를 지칭하는 단어를 임베딩한 단어드렝 걸쳐 작동한다.
- Translate both modalities (image and question) to  "speak the same language"
  - **Modalities**(이미지와 질문)을 모두 **"같은 언어로 말하기"**
- Abstraction over the raw dense features
  - raw dense feature에 관한 추상화
- Inspired by concept learning in humans (cognitive science)
  - 인간의 개념 학습에 영감을 받았다(인지과학).

#### The Neural State Machine for VQA
Given an **image**, we first construct a **scene graph**. Treat it as a state machine
- States correspond to objects
- Transitions correspond to relations.(Edge)
- States have different soft properties (attributes).

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209872603-0447315d-111d-470f-9e0b-0568e2f4c116.png">
</p>

- Objects are represented through a factorized distribution over semantic properties(color, shape, material), defined over the concept vocabulary
  - Object는 개념 어휘에 대해 정의된 의미 속성(색상, 모양, 재료)에 대한 인수 분해된 분포를 통해 표현

<p align="center">
<img width="70%" alt="1" src="https://user-images.githubusercontent.com/111734605/209872752-43ba5d97-7c16-48f1-8a81-63961e649d2e.png">
</p>

- The question is translated into a series of instructions (with attention-based encoder-decoder), defined over the concepts.
  - 질문은 개념에 대해 정의된 일련의 명령(주의 기반 인코더-디코더 사용)으로 변환

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209872890-f01bbced-4f1e-4705-8a61-81cb1a075eab.png">
</p>

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209873022-ec29a5b1-fbee-4ff5-bd26-0334cc2cf82c.png">
</p>

<p align="center">
<img width="100%" alt="1" src="https://user-images.githubusercontent.com/111734605/209873068-9786405d-86cf-42a5-ac81-ecba4218f30b.png">
</p>



## Reference
[The Neural State Machine](https://cs.stanford.edu/people/dorarad/nsm.pdf)
[Paper](https://proceedings.neurips.cc/paper/2019/file/c20a7ce2a627ba838cfbff082db35197-Paper.pdf)
